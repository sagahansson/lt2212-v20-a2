{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "news20 = fetch_20newsgroups(subset='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsdata = news20.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##getting filenames\n",
    "for thefile in news20.filenames:\n",
    "    print(thefile)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allfiles = []\n",
    "onefile = []\n",
    "allwords = []\n",
    "for file in newsdata:\n",
    "    print(file)\n",
    "    onefile = []\n",
    "    lowerfile = file.lower()\n",
    "    print(lowerfile)\n",
    "    break\n",
    "    newfile = lowerfile.split()\n",
    "    for w in newfile:\n",
    "        if w.isalpha():\n",
    "            onefile.append(w)\n",
    "            \n",
    "    allwords.extend(onefile)\n",
    "    allfiles.append((collections.Counter(onefile)))\n",
    "print(len(allwords))\n",
    "print(len(allfiles))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowerfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_to_list(a_sample):\n",
    "    lower = a_sample.lower()\n",
    "    word_strings = lower.split()\n",
    "    only_alpha = [word for word in word_strings if word.isalpha()]\n",
    "    return only_alpha\n",
    "\n",
    "def word_count(nparray):\n",
    "    \n",
    "\n",
    "def extract_features(samples):\n",
    "    \n",
    "    sample_list = []\n",
    "    idx = 0\n",
    "    word_idx = {}\n",
    "    # gör en 0-array med lika många \"lists\" i sig som det finns samples i samples OCH lika många nollor i varje \"list\" som det finns tokens totalt\n",
    "    # -> np.zeros(bredd, höjd) : bredd = antal tokens = len(word_idx), höjd = antal \"dokument\" = len(samples)\n",
    "    for sample in samples:\n",
    "        sample_words = tokenize_to_list(sample)\n",
    "        samples_list.append()\n",
    "        for word in sample_words:\n",
    "            if word not in word_idx:\n",
    "                word_idx[word] = idx\n",
    "                idx += 1\n",
    "    antal_words = len(word_idx)\n",
    "    antal_docs = len(samples)\n",
    "    \n",
    "    nparray = np.zeros((antal_words, antal_docs))\n",
    "    sample_no = 0\n",
    "    for arr in nparray:\n",
    "        # call counter funktion som räknar ord i varje sample + lägger deras värden på rätt plats i rätt arr i nparray\n",
    "    return nparray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize_to_list(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_features(newsdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funkar säkert jättebra men tar fan hundra år\n",
    "#count = 0\n",
    "#print('hello')\n",
    "#for afile in allfiles:\n",
    "#    for word in allwords:\n",
    "#        \n",
    "#        if word not in afile.keys():\n",
    "#            afile.update({word: 0})\n",
    "#        print(count)\n",
    "#        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(allfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {1: \"one\", 2: \"three\"}\n",
    "d1 = {2: \"two\", 3: \"three\"}\n",
    "\n",
    "# updates the value of key 2\n",
    "d.update(d1)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for afile in allfiles:\n",
    "    notinfile = [item for item in allwords if item not in afile.keys()]\n",
    "    dict_value = 0\n",
    "    dict_with0s = dict.fromkeys(notinfile, dict_value)\n",
    "    afile.update(dict_with0s)\n",
    "    print(count)\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for onefile in allfiles:\n",
    "    for key, val in sorted(onefile.items()):\n",
    "        print(key, val)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "little_list = []\n",
    "big_list = []\n",
    "\n",
    "for file in allfiles:\n",
    "    for key, val in sorted(file.items()):\n",
    "        little_list.append(val)\n",
    "    big_list.append(little_list)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
